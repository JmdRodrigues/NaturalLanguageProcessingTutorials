{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "artificial-packaging",
   "metadata": {},
   "source": [
    "# NLP main Python libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-scope",
   "metadata": {},
   "source": [
    "| Library           | Link                                                   | Description                                                                                                                                                                                                                                                                                                                               |\n",
    "|-------------------|--------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| NLTK              | https://www.nltk.org/                                  | NLTK is a platform for building Python programs to work with human language data. It provides text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries. It can be very relevant to pre-process and make a pre-analysis to text data |\n",
    "| Textblob          | https://textblob.readthedocs.io/en/dev/                | TextBlob is a Python (2 and 3) library for processing textual data. It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.                                                            |\n",
    "| Spacy             | https://spacy.io/usage/v3                              | Spacy is a modern industrial-strength NLP library. It provides an exhaustive list of methods, models and tools. It also includes several other projects in the area of NLP and their main brand Explosion.                                                                                                                                |\n",
    "| Gensim            | https://radimrehurek.com/gensim/                       | Gensim is a free open-source Python library for representing documents as semantic vectors, as efficiently (computer-wise) and painlessly (human-wise) as possible. It provides good resources and methods to perform Topic Modelling and distance based text classification.                                                             |\n",
    "| Glove             | https://nlp.stanford.edu/projects/glove/               | GloVe is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space.                                            |\n",
    "| transformer       | https://github.com/huggingface/transformers            | Transformers is a Python library with several pre-trained models and editable models for NLP tasks.                                                                                                                                                                                                                                       |\n",
    "| simpletransformer | https://github.com/ThilinaRajapakse/simpletransformers | Simple transformers wraps \"transformers\" to make it easier to use.                                                                                                                                                                                                                                                                        |\n",
    "| polyglot          | https://polyglot.readthedocs.io/en/latest/             | Polyglot is a Python library that has several tools for NLP in a huge range of different languages.                                                                                                                                                                                                                                       |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-print",
   "metadata": {},
   "source": [
    "## Biomedical NLP libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-bracelet",
   "metadata": {},
   "source": [
    "| Library  | Link                                               | Description                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
    "|----------|----------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| medSpacy | https://github.com/medspacy/medspacy               | MedSpaCy is a library of tools for performing clinical NLP and text processing tasks with the popular spaCy framework. The medspacy package brings together a number of other packages, each of which implements specific functionality for common clinical text processing specific to the clinical domain, such as sentence segmentation, contextual analysis and attribute assertion, and section detection.     |\n",
    "| bioBert  | https://github.com/dmis-lab/biobert                | This repository provides the code for fine-tuning BioBERT, a biomedical language representation model designed for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, question answering, etc. Please refer to our paper BioBERT: a pre-trained biomedical language representation model for biomedical text mining for more details. This project is done by DMIS-Lab. |\n",
    "| sciSpace | https://github.com/allenai/scispacy                | This repository contains custom pipes and models related to using spaCy for scientific documents.                                                                                                                                                                                                                                                                                                                   |\n",
    "| NLPre    | https://github.com/NIHOPA/NLPre                    | NLPre is a text (pre)-processing library that helps smooth some of the inconsistencies found in real-world data. Correcting for issues like random capitalization patterns, strange hyphenations, and abbreviations are essential parts of wrangling textual data but are often left to the user.                                                                                                                   |\n",
    "| covBSV   | https://github.com/abchapman93/VA_COVID-19_NLP_BSV | An NLP pipeline for COVID-19 surveillance used in the Department of Veterans Affairs Biosurveillance. This system is described in A Natural Language Processing System for National COVID-19 Surveillance in the US Department of Veterans Affairs by Chapman et al as part of the ACL COVID-19 Emergency Workshop.                                                                                                 |\n",
    "| Kindred  | https://github.com/jakelever/kindred               | Kindred is a Python3 package for relation extraction in biomedical texts. Given some training data, it can build a model to identify relations between entities (e.g. drugs, genes, etc) in a sentence.                                                                                                                                                                                                             |\n",
    "| Saber    | https://spacy.io/universe/project/saber            | Deep-learning based tool for information extraction in the biomedical domain                                                                                                                                                                                                                                                                                                                                        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-threshold",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
