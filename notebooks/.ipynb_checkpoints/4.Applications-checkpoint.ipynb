{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "african-retrieval",
   "metadata": {},
   "source": [
    "# NLP Applications for Text Mining\n",
    "\n",
    "In this notebook will be showed how to use NLP techniques with Python tools for several examples, following this list:\n",
    "\n",
    "- Part of Speech Tagging (POS)\n",
    "- Named Entity Recognition (NER)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-block",
   "metadata": {},
   "source": [
    "### Part of Speech Tagging\n",
    "\n",
    "Part of Speech Tagging (POS) is the process of identifying the part to which a word belongs in a sentence of a corpus, for instance, if it is a verb, subject or a pronoun. We will use the Spacy framework to show you examples of its usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "architectural-stuart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"8c9eeeddb55547bba59903e17d2e1e52-0\" class=\"displacy\" width=\"1100\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">perform</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">tagging</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">words</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8c9eeeddb55547bba59903e17d2e1e52-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8c9eeeddb55547bba59903e17d2e1e52-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8c9eeeddb55547bba59903e17d2e1e52-0-1\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8c9eeeddb55547bba59903e17d2e1e52-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8c9eeeddb55547bba59903e17d2e1e52-0-2\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8c9eeeddb55547bba59903e17d2e1e52-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M575.0,179.0 L583.0,167.0 567.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8c9eeeddb55547bba59903e17d2e1e52-0-3\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8c9eeeddb55547bba59903e17d2e1e52-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,179.0 L753.0,167.0 737.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8c9eeeddb55547bba59903e17d2e1e52-0-4\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8c9eeeddb55547bba59903e17d2e1e52-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M920.0,179.0 L928.0,167.0 912.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"I perform the tagging of words\")\n",
    "displacy.render(doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "native-fields",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"451e015e8fa34f57a580f23e15984a91-0\" class=\"displacy\" width=\"650\" height=\"237.0\" direction=\"ltr\" style=\"max-width: none; height: 237.0px; color: #2C9CD8; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">perform</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">VBP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\">DT</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">tagging</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">NN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">IN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"550\">words</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"550\">NNS</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-451e015e8fa34f57a580f23e15984a91-0-0\" stroke-width=\"2px\" d=\"M70,102.0 C70,52.0 145.0,52.0 145.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-451e015e8fa34f57a580f23e15984a91-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,104.0 L62,92.0 78,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-451e015e8fa34f57a580f23e15984a91-0-1\" stroke-width=\"2px\" d=\"M270,102.0 C270,52.0 345.0,52.0 345.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-451e015e8fa34f57a580f23e15984a91-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M270,104.0 L262,92.0 278,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-451e015e8fa34f57a580f23e15984a91-0-2\" stroke-width=\"2px\" d=\"M170,102.0 C170,2.0 350.0,2.0 350.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-451e015e8fa34f57a580f23e15984a91-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M350.0,104.0 L358.0,92.0 342.0,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-451e015e8fa34f57a580f23e15984a91-0-3\" stroke-width=\"2px\" d=\"M370,102.0 C370,52.0 445.0,52.0 445.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-451e015e8fa34f57a580f23e15984a91-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M445.0,104.0 L453.0,92.0 437.0,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-451e015e8fa34f57a580f23e15984a91-0-4\" stroke-width=\"2px\" d=\"M470,102.0 C470,52.0 545.0,52.0 545.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-451e015e8fa34f57a580f23e15984a91-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M545.0,104.0 L553.0,92.0 537.0,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options = {\"fine_grained\":True, \"distance\":100, \"color\":\"#2C9CD8\"}\n",
    "displacy.render(doc, style=\"dep\", jupyter=True, options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-bermuda",
   "metadata": {},
   "source": [
    "### Named Entity Recognition (NER)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "changed-milton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    GOOGLE\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " has developed a new algorithm to surpass \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    IBM\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ". </div>\n",
       "\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    John Bugoiggy\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is responsible for developing this strategy, which is believed to be the best of \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the 21st century\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"\"\"GOOGLE has developed a new algorithm to surpass IBM. John Bugoiggy is responsible for developing this strategy, which is believed to be the best of the 21st century.\"\"\"\n",
    "doc = nlp(text)\n",
    "sentence_spans = list(doc.sents)\n",
    "displacy.render(sentence_spans, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-tragedy",
   "metadata": {},
   "source": [
    "## Text Summarization\n",
    "\n",
    "Techniques for text summarization are divided into a) ***abstractive\n",
    "based*** and b) ***extractive based***. Method **a** requires the usage\n",
    "of a more complex process, involving the inference of word and sentence\n",
    "relationships and developing a sentence generator based on the syntactic\n",
    "relationships found. This strategy is supervised and is computationally\n",
    "expensive. In the other end, method **b** is unsupervised and provides a\n",
    "summarization of text by means of ranking the importance of sentences.\n",
    "This importance level is calculated with similarity measures from\n",
    "token/word frequency matrices, such as *BoW* or *TFIDF*. The steps for extractive methods are (1) Compute a normalized term frequency matrix and the total frequency of words in the document; (2) compute the sentence relevance by means of similarity measures or by calculating the sum of the word normalized frequencies that belong to each sentence and (3) sort the sentence by importance level. The summary of the document is then the set of more important sentences.\n",
    "\n",
    "\n",
    "![Caption](Figures/TextSummarize.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-designation",
   "metadata": {},
   "source": [
    "#### Text Summarization with Gensim\n",
    "(Example taken from: [George Pipis](https://python-bloggers.com/2020/09/text-summarization-in-python-with-gensim/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "initial-alias",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The LDA process generates documents based on a probability modulated by the number of topics and words present in documents.', 'The LDA typically accepts a \\textit{BoW} model, from which it derives the topics to which documents are associated based on the words that these contain.']\n"
     ]
    }
   ],
   "source": [
    "from gensim.summarization.summarizer import summarize\n",
    "from gensim.summarization.textcleaner import split_sentences\n",
    "\n",
    "text = \"\"\"The Latent Dirichlet Allocation approach is an unsupervised method used for Topic Modelling that is supported in two main considerations: (1) Documents that have similar words must have similar topics; (2) Documents that have groups of words frequently occurring together usually have the same topic. LDA is a fuzzy clustering method that provides a value that reflects the membership of the sentence into a specific topic. The clustering process is performed based on the adequacy of a sentence to a generated corpus. \n",
    "The LDA process generates documents based on a probability modulated by the number of topics and words present in documents. This probability has the following equation:\n",
    "In the first case, the Dirichlet distribution evaluates the probability of a document belonging to a specific Topic, while the second evaluates the probability of a topic being associated with a word. The triangles can help visualize these distributions. The blue triangle has topics as edges, while documents as elements. The closer the words are from the edges, the closer these are related to that topic. In the other hand, the yellow tetrahedron has words as edges, while topics as elements. The $\\theta$ and $\\phi$ parameters are associated with multinomial distributions corresponding to topics and words, respectively. From these distributions, words and topics are generated and combined to generate a document. The documents are generated based on the arrangement between document-topics probabilities and topic-words probabilities. The generated document that maximizes the probability and best fit the inputted document will be classified based on the arrangement, and be assigned a membership probability to each topic.\n",
    "The LDA typically accepts a \\textit{BoW} model, from which it derives the topics to which documents are associated based on the words that these contain. \\textbf{Examples of applying LDA can be seen in the following \\textit{notebook}}.\"\"\"\n",
    "\n",
    "test_summary = summarize(text, ratio=0.15, split=True)\n",
    "\n",
    "print(test_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-earth",
   "metadata": {},
   "source": [
    "#### Text Summarization with Spacy\n",
    "(Example taken from [Jesse E. Agbe](https://github.com/Jcharis/Natural-Language-Processing-Tutorials/blob/master/NLP_with_SpaCy/Text%20Summarization%20In%20SpaCy.ipynb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "finished-carbon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The generated document that maximizes the probability and best fit the inputted document will be classified based on the arrangement, and be assigned a membership probability to each topic. The LDA typically accepts a \textit{BoW} model, from which it derives the topics to which documents are associated based on the words that these contain. The closer the words are from the edges, the closer these are related to that topic.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# Build an NLP Object\n",
    "docx = nlp(text)\n",
    "# Tokenization of Text\n",
    "mytokens = [token.text for token in docx]\n",
    "#Word Frequency table\n",
    "# Build Word Frequency\n",
    "# word.text is tokenization in spacy\n",
    "word_frequencies = {}\n",
    "for word in docx:\n",
    "        if word.text not in word_frequencies.keys():\n",
    "            word_frequencies[word.text] = 1\n",
    "        else:\n",
    "            word_frequencies[word.text] += 1\n",
    "\n",
    "#Normalize \n",
    "maximum_frequency = max(word_frequencies.values())\n",
    "\n",
    "for word in word_frequencies.keys():  \n",
    "        word_frequencies[word] = (word_frequencies[word]/maximum_frequency)\n",
    "\n",
    "        #sentence list\n",
    "sentence_list = [ sentence for sentence in docx.sents ]\n",
    "[w.text.lower() for t in sentence_list for w in t ]\n",
    "\n",
    "#ranking sentences:\n",
    "sentence_scores = {}  \n",
    "for sent in sentence_list:  \n",
    "        for word in sent:\n",
    "            if word.text.lower() in word_frequencies.keys():\n",
    "                if len(sent.text.split(' ')) < 30:\n",
    "                    if sent not in sentence_scores.keys():\n",
    "                        sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
    "                    else:\n",
    "                        sentence_scores[sent] += word_frequencies[word.text.lower()]\n",
    "\n",
    "sorted_sentences = [sentence[0] for sentence in sorted(sentence_scores.items(), key=lambda value: value[1])[::-1]]\n",
    "\n",
    "#Only print the first 3 sentences\n",
    "final_sentences = [ w.text for w in sorted_sentences[:3]]\n",
    "summary = ' '.join(final_sentences)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-lotus",
   "metadata": {},
   "source": [
    "## Topic Modelling\n",
    "\n",
    "In this example, we will use sklearn and gensim to test several topic modelling strategies. We will 3 datasets (Atheism, Christianism and Graphics). We will test these with LDA, LSI and NMF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "saved-vertex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics']"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Loading a dataset\n",
    "categories = ['alt.atheism', \"comp.graphics\"]\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "train_dataset = fetch_20newsgroups(subset=\"train\", categories=categories, shuffle=True, random_state=42)\n",
    "train_dataset.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "vanilla-prime",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute BoW or TFIDF\n",
    "count_vect = CountVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "doc_term_matrix = count_vect.fit_transform(train_dataset.data)\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(max_df=0.95, min_df=2, stop_words=\"english\", max_features=1000)\n",
    "tfidf_matrix = tfidf_vect.fit_transform(train_dataset.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-liberal",
   "metadata": {},
   "source": [
    "#### Latent Dirichelet Allocation (LDA) with BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "married-recall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 0 0 1 0 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAANx0lEQVR4nO3df6xfd13H8eeLjWkCiGivZFlbOrUkLmhkuRkuEF0iaLeYVaPBNiFhhnD5gxoMxDicGcuMUUCJMZnoNRJ+RCjzF95oTTU6gzHd0jvAQbsMb+ZwrYOVMVFCdE7e/nG/gy93997vub3f29u+7/ORNP1+z/nc+/2ce9pnT8/3nnNTVUiSLn3P2e4JSJKmw6BLUhMGXZKaMOiS1IRBl6QmLt+uF961a1ft27dvu15eki5J999//xerama1ddsW9H379rG4uLhdLy9Jl6Qkn1trnadcJKkJgy5JTRh0SWrCoEtSEwZdkpow6JLUxMSgJ3lfkseTfGaN9UnyO0mWkjyQ5NrpT1OSNMmQI/T3AwfWWX8jsH/0aw547+anJUnaqIlBr6qPA19aZ8hB4IO17F7g25NcOa0JSpKGmcaVolcBj449PzNa9tjKgUnmWD6KZ+/evZt/5ff/xOQxt/zl1o4f/5iLbfzQj7lAX6ND8yeGjR05Onf9pfs12sycLrbxQz+m09do6MdsZvwWuKCX/lfVPDAPMDs7649K2kLfiOdtkwePxh6du37rJqRLkn+OLi3TCPpZYM/Y892jZdKOtxzEATEEmD9hDLUp0wj6AnAkyVHgFcCXq+pZp1ukjdpoDJcZT+1cE4Oe5CPADcCuJGeAdwDPBaiq3wOOATcBS8BXgZ/bqsnuZOcXN02b+0EXs4lBr6rDE9YX8OapzUiSdF68UlSSmjDoktSEQZekJgy6JDVh0CWpiW37IdEXkle7SdoJPEKXpCYMuiQ1YdAlqQmDLklN7Ig3RTXM4PuU+MaxdFHyCF2SmvAIXTvW+Xw7q3Qx8whdkpow6JLUhEGXpCYMuiQ14Zuia/CH+0q61HiELklNGHRJasKgS1ITnkPXedvo+wyStpZH6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgYFPcmBJA8lWUpy6yrr9ya5J8knkzyQ5KbpT1WStJ6JQU9yGXAXcCNwDXA4yTUrhv0KcHdVvRw4BPzutCcqSVrfkCP064Clqnq4qp4CjgIHV4wp4NtGj18I/Pv0pihJGmJI0K8CHh17fma0bNwdwOuSnAGOAT+/2idKMpdkMcniuXPnzmO6kqS1TOtN0cPA+6tqN3AT8KEkz/rcVTVfVbNVNTszMzOll5YkwbCgnwX2jD3fPVo27g3A3QBVdQL4VmDXNCYoSRpmSNBPAvuTXJ3kCpbf9FxYMebfgB8FSPJ9LAfdcyqSdAFNDHpVPQ0cAY4DD7L83SynktyZ5ObRsLcBb0zyz8BHgFuqqrZq0pKkZxv0I+iq6hjLb3aOL7t97PFp4JXTnZokaSP8maKSWtvoz749Onf9ls5nK3npvyQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1cfl2T6CLQ/MngNuGDZ4/wdG567d0PpJ2Ho/QJakJgy5JTRh0SWrCoEtSEwZdkpoYFPQkB5I8lGQpya1rjHltktNJTiX58HSnKUmaZOK3LSa5DLgLeA1wBjiZZKGqTo+N2Q+8HXhlVT2Z5Lu2asKSpNUNOUK/Dliqqoer6ingKHBwxZg3AndV1ZMAVfX4dKcpSZpkSNCvAh4de35mtGzcS4GXJvmnJPcmOTCtCUqShpnWlaKXA/uBG4DdwMeTfH9V/cf4oCRzwBzA3r17p/TSkiQYdoR+Ftgz9nz3aNm4M8BCVf1vVf0r8FmWA/9Nqmq+qmaranZmZuZ85yxJWsWQoJ8E9ie5OskVwCFgYcWYj7F8dE6SXSyfgnl4etOUJE0yMehV9TRwBDgOPAjcXVWnktyZ5ObRsOPAE0lOA/cAv1hVT2zVpCVJzzboHHpVHQOOrVh2+9jjAt46+iVJ2gZeKSpJTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNDAp6kgNJHkqylOTWdcb9dJJKMju9KUqShpgY9CSXAXcBNwLXAIeTXLPKuBcAbwHum/YkJUmTDTlCvw5YqqqHq+op4ChwcJVxvwq8E/jvKc5PkjTQkKBfBTw69vzMaNnXJbkW2FNVf7XeJ0oyl2QxyeK5c+c2PFlJ0to2/aZokucA7wHeNmlsVc1X1WxVzc7MzGz2pSVJY4YE/SywZ+z57tGyZ7wAeBnwD0keAX4IWPCNUUm6sIYE/SSwP8nVSa4ADgELz6ysqi9X1a6q2ldV+4B7gZuranFLZixJWtXEoFfV08AR4DjwIHB3VZ1KcmeSm7d6gpKkYS4fMqiqjgHHViy7fY2xN2x+WpKkjfJKUUlqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTQwKepIDSR5KspTk1lXWvzXJ6SQPJPm7JC+Z/lQlSeuZGPQklwF3ATcC1wCHk1yzYtgngdmq+gHgT4B3TXuikqT1DTlCvw5YqqqHq+op4ChwcHxAVd1TVV8dPb0X2D3daUqSJhkS9KuAR8eenxktW8sbgL9ebUWSuSSLSRbPnTs3fJaSpImm+qZoktcBs8C7V1tfVfNVNVtVszMzM9N8aUna8S4fMOYssGfs+e7Rsm+S5NXAbcCPVNX/TGd6kqShhhyhnwT2J7k6yRXAIWBhfECSlwO/D9xcVY9Pf5qSpEkmBr2qngaOAMeBB4G7q+pUkjuT3Dwa9m7g+cAfJ/lUkoU1Pp0kaYsMOeVCVR0Djq1YdvvY41dPeV6SpA3ySlFJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUxKAfEi1JF4tD8yeA24YNnj+xpXO52HiELklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhPey2WbeD8KaZl/F6Zn0BF6kgNJHkqylOTWVdZ/S5KPjtbfl2Tf1GcqSVrXxCP0JJcBdwGvAc4AJ5MsVNXpsWFvAJ6squ9Ncgh4J/CzWzFhqbONHq0enbt+Sz+/Jjv09a/TgK/raOxG99tQqar1ByTXA3dU1Y+Pnr8doKp+fWzM8dGYE0kuBz4PzNQ6n3x2drYWFxfPa9KH/IMm6RK2maAnub+qZldbN+Qc+lXAo2PPzwCvWGtMVT2d5MvAdwJfXDGROWBu9PQrSR4a8PobsWvla+4AbvPO4DY38tE3rblqyDa/ZK0VF/RN0aqaB+a36vMnWVzrX66u3OadwW3eGTa7zUPeFD0L7Bl7vnu0bNUxo1MuLwSeON9JSZI2bkjQTwL7k1yd5ArgELCwYswC8PrR458B/n698+eSpOmbeMpldE78CHAcuAx4X1WdSnInsFhVC8AfAh9KsgR8ieXob4ctO51zEXObdwa3eWfY1DZP/C4XSdKlwUv/JakJgy5JTbQJ+qTbE3SU5JEkn07yqSTnd5XWRS7J+5I8nuQzY8u+I8nfJvmX0e8v2s45Ttsa23xHkrOjff2pJDdt5xynKcmeJPckOZ3kVJK3jJa33c/rbPOm9nOLc+ij2xN8lrHbEwCHV9yeoJ0kjwCzVdXy4guAJD8MfAX4YFW9bLTsXcCXquo3Rv94v6iqfmk75zlNa2zzHcBXquo3t3NuWyHJlcCVVfWJJC8A7gd+EriFpvt5nW1+LZvYz12O0K8Dlqrq4ap6CjgKHNzmOWkKqurjLH/n1LiDwAdGjz/A8l+ENtbY5raq6rGq+sTo8X8BD7J89Xnb/bzONm9Kl6CvdnuCTX9xLgEF/E2S+0e3VdgpXlxVj40efx548XZO5gI6kuSB0SmZNqcfxo3u1Ppy4D52yH5esc2wif3cJeg71auq6lrgRuDNo/+q7yijC9gu/fOGk70X+B7gB4HHgN/a1tlsgSTPB/4U+IWq+s/xdV338yrbvKn93CXoQ25P0E5VnR39/jjw5yyfetoJvjA6B/nMucjHt3k+W66qvlBV/1dVXwP+gGb7OslzWQ7bH1XVn40Wt97Pq23zZvdzl6APuT1BK0meN3ozhSTPA34M+Mz6H9XG+K0mXg/8xTbO5YJ4JmwjP0WjfZ0kLF9t/mBVvWdsVdv9vNY2b3Y/t/guF4DRt/f8Nt+4PcGvbe+MtlaS72b5qByWb+Hw4Y7bnOQjwA0s31b0C8A7gI8BdwN7gc8Br62qNm8irrHNN7D83/ACHgHeNHZ++ZKW5FXAPwKfBr42WvzLLJ9Tbrmf19nmw2xiP7cJuiTtdF1OuUjSjmfQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUxP8Dq3oFj+xAA+sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "#Start LDA transformer\n",
    "LDA = LatentDirichletAllocation(n_components=2, random_state=42)\n",
    "LDA.fit(doc_term_matrix)\n",
    "\n",
    "#fit and transform matrix\n",
    "topic_values = LDA.transform(doc_term_matrix)\n",
    "docs = 25\n",
    "labels = range(docs)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(labels, topic_values[:docs,0], 1, alpha=0.75)\n",
    "ax.bar(labels, topic_values[:docs,1], bottom=topic_values[:docs,0], alpha=0.75)\n",
    "# ax.bar(labels, topic_values[:docs,2], bottom=topic_values[:docs,1], alpha=0.75)\n",
    "print(train_dataset.target[:docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-continent",
   "metadata": {},
   "source": [
    "#### Latent Dirichelet Allocation (LDA) with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "outdoor-surrey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Class for Document\n",
      "[0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 0 0 1 0 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Start LDA transformer\n",
    "LDA = LatentDirichletAllocation(n_components=2, random_state=42)\n",
    "LDA.fit(tfidf_matrix)\n",
    "\n",
    "#fit and transform matrix\n",
    "topic_values = LDA.transform(tfidf_matrix)\n",
    "docs = 25\n",
    "labels = range(docs)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(labels, topic_values[:docs,0], 1, alpha=0.75)\n",
    "ax.bar(labels, topic_values[:docs,1], bottom=topic_values[:docs,0], alpha=0.75)\n",
    "# ax.bar(labels, topic_values[:docs,2], bottom=topic_values[:docs,1], alpha=0.75)\n",
    "print(\"Target Class for Document\")\n",
    "print(train_dataset.target[:docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "least-worthy",
   "metadata": {},
   "source": [
    "#### Non Negative Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "forty-withdrawal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\biosignals3\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:312: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn((\"The 'init' value, when 'init=None' and \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\n",
      "[0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 0 0 1 0 0]\n",
      "Predicted:\n",
      "[1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "n_components = 2\n",
    "\n",
    "nmf = NMF(n_components=n_components, random_state=1,\n",
    "          beta_loss=\"kullback-leibler\", solver=\"mu\", max_iter=1000, alpha=.1, l1_ratio=.5).fit(tfidf_matrix)\n",
    "\n",
    "topic_values = nmf.transform(tfidf_matrix)\n",
    "pred = topic_values.argmax(axis=1)\n",
    "\n",
    "print(\"Target:\")\n",
    "print(train_dataset.target[:docs])\n",
    "print(\"Predicted:\")\n",
    "print(pred[:docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-municipality",
   "metadata": {},
   "source": [
    "#### Latent Semantic Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "beneficial-corner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(15313 unique tokens: ['125245', '12872', '1993apr15', '1qie61', '2000']...)\n",
      "Targeted:\n",
      "[0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 0 0 1 0 0]\n",
      "Predicted:\n",
      "[0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from gensim import models\n",
    "from gensim import corpora\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "from nltk import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "documents = train_dataset.data\n",
    "eng_stopwords = set(nlp.Defaults.stop_words)\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\s+', gaps=True)\n",
    "stemmer = PorterStemmer()\n",
    "translate_tab = {ord(p): u\" \" for p in punctuation}\n",
    "\n",
    "def text2tokens(raw_text):\n",
    "    \"\"\"Split the raw_text string into a list of stemmed tokens.\"\"\"\n",
    "    clean_text = raw_text.lower().translate(translate_tab)\n",
    "    tokens = [token.strip() for token in tokenizer.tokenize(clean_text)]\n",
    "    tokens = [token for token in tokens if token not in eng_stopwords]\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return [token for token in stemmed_tokens if len(token) > 2]  # skip short tokens\n",
    "\n",
    "\n",
    "dataset = [text2tokens(txt) for txt in documents]  # convert a documents to list of tokens\n",
    "\n",
    "dictionary = corpora.Dictionary(dataset)\n",
    "print(dictionary)\n",
    "corpus = [dictionary.doc2bow(text) for text in dataset]\n",
    "\n",
    "tfidf = models.TfidfModel(corpus)  # step 1 -- initialize a model\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "lsi_model = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=300)  # initialize an LSI transformation\n",
    "corpus_lsi = lsi_model[corpus_tfidf] \n",
    "\n",
    "# From the lsi_model we get new vectors\n",
    "from gensim import similarities\n",
    "index = similarities.MatrixSimilarity(corpus_lsi)\n",
    "self_sims = index[corpus_lsi]\n",
    "\n",
    "#From LSI we converted the TFIDF to LSI vector space. Now, to get the classification, we should cluster the similarity matrix\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(self_sims)\n",
    "pred = kmeans.labels_\n",
    "\n",
    "print(\"Targeted:\")\n",
    "print(train_dataset.target[:25])\n",
    "print(\"Predicted:\")\n",
    "print(pred[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-candidate",
   "metadata": {},
   "source": [
    "### Main Conclusion\n",
    "\n",
    "- LDA works better than the remaining methods\n",
    "- NMF did not perform well\n",
    "- LSI works well based on the distance of vectors\n",
    "\n",
    "- LDA works better with BoW\n",
    "- LSI works better with TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-identifier",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "adjusted-lloyd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "import pandas as pd\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "spacy_text_blob = SpacyTextBlob()\n",
    "nlp.add_pipe(spacy_text_blob)\n",
    "text = 'I had a really horrible day. It was the worst day ever! But every now and then I have a really good day that makes me happy.'\n",
    "doc = nlp(text)\n",
    "\n",
    "doc._.sentiment.polarity      # Polarity: -0.125\n",
    "doc._.sentiment.subjectivity  # Sujectivity: 0.9\n",
    "doc._.sentiment.assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "monetary-trader",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Sentiment\n",
       "0  A very, very, very slow-moving, aimless movie ...          0\n",
       "1  Not sure who was more lost - the flat characte...          0\n",
       "2  Attempting artiness with black & white and cle...          0\n",
       "3       Very little music or anything to speak of.            0\n",
       "4  The best scene in the movie was when Gerardo i...          1"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load IMDB data\n",
    "columns_name = ['Review', 'Sentiment']\n",
    "data_imdb = pd.read_csv('Data/imdb_labelled.txt', sep = '\\t', header = None)\n",
    "data_imdb.columns = columns_name\n",
    "data_imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-stock",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-guitar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-rescue",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-slope",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "great-prior",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "#### POS and NER\n",
    "\n",
    "- https://spacy.io/usage/rule-based-matching#dependencymatcher\n",
    "\n",
    "#### Text Summarization\n",
    "- https://python-bloggers.com/2020/09/text-summarization-in-python-with-gensim/\n",
    "- https://medium.com/analytics-vidhya/text-summarization-using-spacy-ca4867c6b744\n",
    "- https://medium.com/analytics-vidhya/nlp-text-summarization-an-overview-bc105810f71e\n",
    "- https://towardsdatascience.com/simple-text-summarization-in-python-bdf58bfee77f\n",
    "- https://predictivehacks.com/text-summarization-in-python-with-gensim/\n",
    "- https://github.com/Jcharis/Natural-Language-ProcessingTutorials/blob/master/NLP_with_SpaCy/Text%20Summarization%20In%20SpaCy.ipynb\n",
    "- https://arxiv.org/pdf/1602.03606.pdf\n",
    "- https://www.aclweb.org/anthology/W04-3252.pdf\n",
    "- https://towardsdatascience.com/understand-text-summarization-and-create-your-own-summarizer-in-python-b26a9f09fc70\n",
    "- https://arxiv.org/pdf/1707.02268v3.pdf\n",
    "- https://arxiv.org/pdf/1703.09902v1.pdf\n",
    "\n",
    "#### Topic Modelling\n",
    "- https://radimrehurek.com/gensim/auto_examples/core/run_topics_and_transformations.html#sphx-glr-auto-examples-core-run-topics-and-transformations-py\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "- https://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html#sphx-glr-auto-examples-applications-plot-topics-extraction-with-nmf-lda-py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-sweet",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
